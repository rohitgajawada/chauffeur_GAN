steer shape (50000,)
labels shape  (50000,)
Configurations of  all_da
GANMODEL_NAME LSDcontrol_task_2d
LOSS_FUNCTION WGANmix
LR_G, LR_D, LR 0.0002 0.0002 0.0002
SKIP 0
TYPE task1
L1 WEIGHT 1.0
TASK ADV WEIGHT 0.1
LAB SMOOTH 1
Loading IL
70 88
Transferring  p1.0.layers.0.0.weight  to  perception.0.layers.0.0.weight
Transferring  p1.0.layers.0.0.bias  to  perception.0.layers.0.0.bias
Transferring  p1.0.layers.0.1.weight  to  perception.0.layers.0.1.weight
Transferring  p1.0.layers.0.1.bias  to  perception.0.layers.0.1.bias
Transferring  p1.0.layers.0.1.running_mean  to  perception.0.layers.0.1.running_mean
Transferring  p1.0.layers.0.1.running_var  to  perception.0.layers.0.1.running_var
Transferring  p1.0.layers.1.0.weight  to  perception.0.layers.1.0.weight
Transferring  p1.0.layers.1.0.bias  to  perception.0.layers.1.0.bias
Transferring  p1.0.layers.1.1.weight  to  perception.0.layers.1.1.weight
Transferring  p1.0.layers.1.1.bias  to  perception.0.layers.1.1.bias
Transferring  p1.0.layers.1.1.running_mean  to  perception.0.layers.1.1.running_mean
Transferring  p1.0.layers.1.1.running_var  to  perception.0.layers.1.1.running_var
Transferring  p1.0.layers.2.0.weight  to  perception.0.layers.2.0.weight
Transferring  p1.0.layers.2.0.bias  to  perception.0.layers.2.0.bias
Transferring  p1.0.layers.2.1.weight  to  perception.0.layers.2.1.weight
Transferring  p1.0.layers.2.1.bias  to  perception.0.layers.2.1.bias
Transferring  p1.0.layers.2.1.running_mean  to  perception.0.layers.2.1.running_mean
Transferring  p1.0.layers.2.1.running_var  to  perception.0.layers.2.1.running_var
Transferring  p2.0.layers.0.0.weight  to  perception.0.layers.3.0.weight
Transferring  p2.0.layers.0.0.bias  to  perception.0.layers.3.0.bias
Transferring  p2.0.layers.0.1.weight  to  perception.0.layers.3.1.weight
Transferring  p2.0.layers.0.1.bias  to  perception.0.layers.3.1.bias
Transferring  p2.0.layers.0.1.running_mean  to  perception.0.layers.3.1.running_mean
Transferring  p2.0.layers.0.1.running_var  to  perception.0.layers.3.1.running_var
Transferring  p2.0.layers.1.0.weight  to  perception.0.layers.4.0.weight
Transferring  p2.0.layers.1.0.bias  to  perception.0.layers.4.0.bias
Transferring  p2.0.layers.1.1.weight  to  perception.0.layers.4.1.weight
Transferring  p2.0.layers.1.1.bias  to  perception.0.layers.4.1.bias
Transferring  p2.0.layers.1.1.running_mean  to  perception.0.layers.4.1.running_mean
Transferring  p2.0.layers.1.1.running_var  to  perception.0.layers.4.1.running_var
Transferring  p3.0.layers.0.0.weight  to  perception.0.layers.5.0.weight
Transferring  p3.0.layers.0.0.bias  to  perception.0.layers.5.0.bias
Transferring  p3.0.layers.0.1.weight  to  perception.0.layers.5.1.weight
Transferring  p3.0.layers.0.1.bias  to  perception.0.layers.5.1.bias
Transferring  p3.0.layers.0.1.running_mean  to  perception.0.layers.5.1.running_mean
Transferring  p3.0.layers.0.1.running_var  to  perception.0.layers.5.1.running_var
Transferring  p3.0.layers.1.0.weight  to  perception.0.layers.6.0.weight
Transferring  p3.0.layers.1.0.bias  to  perception.0.layers.6.0.bias
Transferring  p3.0.layers.1.1.weight  to  perception.0.layers.6.1.weight
Transferring  p3.0.layers.1.1.bias  to  perception.0.layers.6.1.bias
Transferring  p3.0.layers.1.1.running_mean  to  perception.0.layers.6.1.running_mean
Transferring  p3.0.layers.1.1.running_var  to  perception.0.layers.6.1.running_var
Transferring  perception_bottom.0.layers.0.0.weight  to  perception.0.layers.7.0.weight
Transferring  perception_bottom.0.layers.0.0.bias  to  perception.0.layers.7.0.bias
Transferring  perception_bottom.0.layers.0.1.weight  to  perception.0.layers.7.1.weight
Transferring  perception_bottom.0.layers.0.1.bias  to  perception.0.layers.7.1.bias
Transferring  perception_bottom.0.layers.0.1.running_mean  to  perception.0.layers.7.1.running_mean
Transferring  perception_bottom.0.layers.0.1.running_var  to  perception.0.layers.7.1.running_var
Transferring  perception_bottom.1.layers.0.0.weight  to  perception.1.layers.0.0.weight
Transferring  perception_bottom.1.layers.0.0.bias  to  perception.1.layers.0.0.bias
Transferring  perception_bottom.1.layers.1.0.weight  to  perception.1.layers.1.0.weight
Transferring  perception_bottom.1.layers.1.0.bias  to  perception.1.layers.1.0.bias
Transferring  measurements.layers.0.0.weight  to  measurements.layers.0.0.weight
Transferring  measurements.layers.0.0.bias  to  measurements.layers.0.0.bias
Transferring  measurements.layers.1.0.weight  to  measurements.layers.1.0.weight
Transferring  measurements.layers.1.0.bias  to  measurements.layers.1.0.bias
Transferring  join.after_process.layers.0.0.weight  to  join.after_process.layers.0.0.weight
Transferring  join.after_process.layers.0.0.bias  to  join.after_process.layers.0.0.bias
Transferring  speed_branch.layers.0.0.weight  to  speed_branch.layers.0.0.weight
Transferring  speed_branch.layers.0.0.bias  to  speed_branch.layers.0.0.bias
Transferring  speed_branch.layers.1.0.weight  to  speed_branch.layers.1.0.weight
Transferring  speed_branch.layers.1.0.bias  to  speed_branch.layers.1.0.bias
Transferring  speed_branch.layers.2.0.weight  to  speed_branch.layers.2.0.weight
Transferring  speed_branch.layers.2.0.bias  to  speed_branch.layers.2.0.bias
Transferring  branch.layers.0.0.weight  to  branches.branched_modules.0.layers.0.0.weight
Transferring  branch.layers.0.0.bias  to  branches.branched_modules.0.layers.0.0.bias
Transferring  branch.layers.1.0.weight  to  branches.branched_modules.0.layers.1.0.weight
Transferring  branch.layers.1.0.bias  to  branches.branched_modules.0.layers.1.0.bias
Transferring  branch.layers.2.0.weight  to  branches.branched_modules.0.layers.2.0.weight
Transferring  branch.layers.2.0.bias  to  branches.branched_modules.0.layers.2.0.bias
IL Model Loaded!
Loading Decoder
24 24
Transferring  stage1_upsample.0.weight  to  stage1_upsample.0.weight
Transferring  stage1_upsample.0.bias  to  stage1_upsample.0.bias
Transferring  stage1_upsample.3.conv_layer.weight  to  stage1_upsample.3.conv_layer.weight
Transferring  stage1_upsample.3.conv_layer.bias  to  stage1_upsample.3.conv_layer.bias
Transferring  stage1_upsample.4.conv_layer.weight  to  stage1_upsample.4.conv_layer.weight
Transferring  stage1_upsample.4.conv_layer.bias  to  stage1_upsample.4.conv_layer.bias
Transferring  stage1_upsample.5.conv_layer.weight  to  stage1_upsample.5.conv_layer.weight
Transferring  stage1_upsample.5.conv_layer.bias  to  stage1_upsample.5.conv_layer.bias
Transferring  stage2_upsample.0.weight  to  stage2_upsample.0.weight
Transferring  stage2_upsample.0.bias  to  stage2_upsample.0.bias
Transferring  stage2_upsample.3.conv_layer.weight  to  stage2_upsample.3.conv_layer.weight
Transferring  stage2_upsample.3.conv_layer.bias  to  stage2_upsample.3.conv_layer.bias
Transferring  stage2_upsample.4.conv_layer.weight  to  stage2_upsample.4.conv_layer.weight
Transferring  stage2_upsample.4.conv_layer.bias  to  stage2_upsample.4.conv_layer.bias
Transferring  stage2_upsample.5.conv_layer.weight  to  stage2_upsample.5.conv_layer.weight
Transferring  stage2_upsample.5.conv_layer.bias  to  stage2_upsample.5.conv_layer.bias
Transferring  stage3_upsample.0.weight  to  stage3_upsample.0.weight
Transferring  stage3_upsample.0.bias  to  stage3_upsample.0.bias
Transferring  stage3_upsample.3.conv_layer.weight  to  stage3_upsample.3.conv_layer.weight
Transferring  stage3_upsample.3.conv_layer.bias  to  stage3_upsample.3.conv_layer.bias
Transferring  stage3_upsample.4.conv_layer.weight  to  stage3_upsample.4.conv_layer.weight
Transferring  stage3_upsample.4.conv_layer.bias  to  stage3_upsample.4.conv_layer.bias
Transferring  stage4_upsample.0.weight  to  stage4_upsample.0.weight
Transferring  stage4_upsample.0.bias  to  stage4_upsample.0.bias
Decoder Model Loaded!
initialize network with normal
initialize network with normal
_netD_bin(
  (main_model): Sequential(
    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 0))
    (1): LeakyReLU(negative_slope=0.2, inplace)
    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 0))
    (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (4): LeakyReLU(negative_slope=0.2, inplace)
    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 0))
    (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (7): LeakyReLU(negative_slope=0.2, inplace)
    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 0))
    (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (10): LeakyReLU(negative_slope=0.2, inplace)
  )
  (bin_model): Sequential(
    (0): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 0))
    (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (2): LeakyReLU(negative_slope=0.2, inplace)
    (3): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 0))
  )
)
_netD_aux(
  (main_model): Sequential(
    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 0))
    (1): LeakyReLU(negative_slope=0.2, inplace)
    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 0))
    (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (4): LeakyReLU(negative_slope=0.2, inplace)
    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 0))
    (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (7): LeakyReLU(negative_slope=0.2, inplace)
    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 0))
    (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (10): LeakyReLU(negative_slope=0.2, inplace)
  )
  (aux_model): Sequential(
    (0): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (2): LeakyReLU(negative_slope=0.2, inplace)
    (3): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))
  )
)
_netF(
  (p1): Sequential(
    (0): Conv(
      (layers): Sequential(
        (0): Sequential(
          (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(2, 2))
          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Dropout2d(p=0.2)
          (3): ReLU(inplace)
        )
        (1): Sequential(
          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Dropout2d(p=0.4)
          (3): ReLU(inplace)
        )
        (2): Sequential(
          (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2))
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Dropout2d(p=0.4)
          (3): ReLU(inplace)
        )
      )
    )
  )
  (p2): Sequential(
    (0): Conv(
      (layers): Sequential(
        (0): Sequential(
          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Dropout2d(p=0.4)
          (3): ReLU(inplace)
        )
        (1): Sequential(
          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2))
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Dropout2d(p=0.4)
          (3): ReLU(inplace)
        )
      )
    )
  )
  (p3): Sequential(
    (0): Conv(
      (layers): Sequential(
        (0): Sequential(
          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Dropout2d(p=0.4)
          (3): ReLU(inplace)
        )
        (1): Sequential(
          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Dropout2d(p=0.4)
          (3): ReLU(inplace)
        )
      )
    )
  )
  (perception_bottom): Sequential(
    (0): Conv(
      (layers): Sequential(
        (0): Sequential(
          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Dropout2d(p=0.4)
          (3): ReLU(inplace)
        )
      )
    )
    (1): FC(
      (layers): Sequential(
        (0): Sequential(
          (0): Linear(in_features=8192, out_features=512, bias=True)
          (1): Dropout2d(p=0.5)
          (2): ReLU(inplace)
        )
        (1): Sequential(
          (0): Linear(in_features=512, out_features=512, bias=True)
          (1): Dropout2d(p=0.5)
          (2): ReLU(inplace)
        )
      )
    )
  )
  (measurements): FC(
    (layers): Sequential(
      (0): Sequential(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Dropout2d(p=0.5)
        (2): ReLU(inplace)
      )
      (1): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): Dropout2d(p=0.5)
        (2): ReLU(inplace)
      )
    )
  )
  (join): Join(
    (after_process): FC(
      (layers): Sequential(
        (0): Sequential(
          (0): Linear(in_features=640, out_features=512, bias=True)
          (1): Dropout2d(p=0.5)
          (2): ReLU(inplace)
        )
      )
    )
  )
  (speed_branch): FC(
    (layers): Sequential(
      (0): Sequential(
        (0): Linear(in_features=512, out_features=256, bias=True)
        (1): Dropout2d(p=0.5)
        (2): ReLU(inplace)
      )
      (1): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Dropout2d(p=0.5)
        (2): ReLU(inplace)
      )
      (2): Sequential(
        (0): Linear(in_features=256, out_features=1, bias=True)
        (1): Dropout2d(p=0.0)
        (2): ReLU(inplace)
      )
    )
  )
  (branch): FC(
    (layers): Sequential(
      (0): Sequential(
        (0): Linear(in_features=512, out_features=256, bias=True)
        (1): Dropout2d(p=0.5)
        (2): ReLU(inplace)
      )
      (1): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Dropout2d(p=0.5)
        (2): ReLU(inplace)
      )
      (2): Sequential(
        (0): Linear(in_features=256, out_features=3, bias=True)
        (1): Dropout2d(p=0.0)
      )
    )
  )
)
_netG(
  (stage1_upsample): Sequential(
    (0): ConvTranspose2d(256, 256, kernel_size=(7, 7), stride=(1, 1))
    (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (2): ReLU(inplace)
    (3): ResnetBlock(
      (conv_layer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dropout): Dropout(p=0.5)
      (activation): ReLU(inplace)
      (normalization_layer): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    )
    (4): ResnetBlock(
      (conv_layer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dropout): Dropout(p=0.5)
      (activation): ReLU(inplace)
      (normalization_layer): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    )
    (5): ResnetBlock(
      (conv_layer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dropout): Dropout(p=0.5)
      (activation): ReLU(inplace)
      (normalization_layer): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    )
  )
  (stage2_upsample): Sequential(
    (0): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (2): ReLU(inplace)
    (3): ResnetBlock(
      (conv_layer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dropout): Dropout(p=0.5)
      (activation): ReLU(inplace)
      (normalization_layer): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    )
    (4): ResnetBlock(
      (conv_layer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dropout): Dropout(p=0.5)
      (activation): ReLU(inplace)
      (normalization_layer): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    )
    (5): ResnetBlock(
      (conv_layer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dropout): Dropout(p=0.5)
      (activation): ReLU(inplace)
      (normalization_layer): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    )
  )
  (stage3_upsample): Sequential(
    (0): ConvTranspose2d(256, 128, kernel_size=(5, 5), stride=(2, 2))
    (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (2): ReLU(inplace)
    (3): ResnetBlock(
      (conv_layer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dropout): Dropout(p=0.5)
      (activation): ReLU(inplace)
      (normalization_layer): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    )
    (4): ResnetBlock(
      (conv_layer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dropout): Dropout(p=0.5)
      (activation): ReLU(inplace)
      (normalization_layer): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    )
  )
  (stage4_upsample): Sequential(
    (0): ConvTranspose2d(128, 3, kernel_size=(8, 8), stride=(2, 2))
    (1): Sigmoid()
  )
)
Using cross entropy!
----------------
Discriminator aux label size HERE torch.Size([4, 4])
tensor([[-0.8149, -0.6097,  0.6176, -0.1653],
        [-0.0184, -0.9581, -0.4043,  1.0191],
        [ 0.4191,  0.1387,  0.3026,  0.3283],
        [-1.3046, -0.5507,  0.5500, -0.1557]], device='cuda:0') tensor([ 0,  0,  0,  0], device='cuda:0')
Some discriminator outputs::  tensor([-0.8149, -0.6097,  0.6176, -0.1653], device='cuda:0') tensor([-0.3008,  0.2610, -0.2741, -0.2548], device='cuda:0') tensor([-0.6214, -0.0320,  0.7557,  0.1958], device='cuda:0') tensor([ 0.0352, -0.2283,  0.9749, -0.1388], device='cuda:0')
Discriminator aux label size HERE torch.Size([4, 4])
tensor([[-0.0197, -0.7997, -2.4143, -0.7687],
        [ 1.2285, -1.6903, -1.0550,  0.4051],
        [-2.1644, -0.6389, -0.2007, -1.1597],
        [-0.3937, -0.2035, -0.1390, -0.9285]], device='cuda:0') tensor([ 0,  0,  0,  0], device='cuda:0')
Some discriminator outputs::  tensor([-0.0197, -0.7997, -2.4143, -0.7687], device='cuda:0') tensor([-2.0848, -2.3751, -1.1897,  0.4355], device='cuda:0') tensor([-0.0554, -0.4416, -0.6128, -0.2415], device='cuda:0') tensor([-1.8367, -1.8408, -3.3009,  4.9183], device='cuda:0')
Discriminator aux label size HERE torch.Size([4, 4])
tensor([[ 0.4506, -0.8286, -2.5649, -0.8057],
        [ 0.0104,  0.6841,  0.2290, -0.2190],
        [ 0.1929,  2.3775,  0.0203, -2.4870],
        [ 0.2918, -0.7751, -0.5831, -1.1867]], device='cuda:0') tensor([ 0,  0,  0,  0], device='cuda:0')
Some discriminator outputs::  tensor([ 0.4506, -0.8286, -2.5649, -0.8057], device='cuda:0') tensor([ 1.4790, -1.4036, -3.3687, -0.1215], device='cuda:0') tensor([ 0.9673,  2.1250,  3.0391, -1.2683], device='cuda:0') tensor([-1.3332, -1.2102, -3.2733,  5.1423], device='cuda:0')
Discriminator aux label size HERE torch.Size([4, 4])
tensor([[ 3.6610,  0.2518, -1.0365, -2.2881],
        [ 2.0512,  0.0094, -1.4786, -0.5963],
        [ 3.8077,  3.1762, -1.3188, -0.8072],
        [ 2.5547,  0.3984,  1.9874, -1.2129]], device='cuda:0') tensor([ 0,  0,  0,  0], device='cuda:0')
Some discriminator outputs::  tensor([ 3.6610,  0.2518, -1.0365, -2.2881], device='cuda:0') tensor([ 2.8918,  0.2283, -1.2278, -2.8527], device='cuda:0') tensor([ 0.5858,  2.1911,  3.7185, -2.0411], device='cuda:0') tensor([-0.3546, -1.2333, -3.2073,  5.0314], device='cuda:0')
Discriminator aux label size HERE torch.Size([4, 4])
tensor([[ 3.4381,  5.1284, -2.0316, -3.1187],
        [ 1.4699,  1.0693,  1.0684, -0.7545],
        [ 2.8017,  0.7815, -0.5657, -1.3514],
        [ 3.1668,  2.0953,  1.0990, -3.2532]], device='cuda:0') tensor([ 0,  0,  0,  0], device='cuda:0')
Some discriminator outputs::  tensor([ 3.4381,  5.1284, -2.0316, -3.1187], device='cuda:0') tensor([ 3.7226,  4.3107, -1.0998, -2.4795], device='cuda:0') tensor([-0.3384,  2.0686,  3.6994, -2.0057], device='cuda:0') tensor([-0.6328, -0.9683, -2.9309,  5.2589], device='cuda:0')
