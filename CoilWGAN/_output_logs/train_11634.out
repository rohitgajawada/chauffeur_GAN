steer shape (50000,)
labels shape  (50000,)
Configurations of  exp_WGANGP_PretrainedF_IL_withL1
GANMODEL_NAME LSDcontrol_task
LOSS_FUNCTION NORMAL
LR_G, LR_D, LR 0.0002 0.0002 0.0002
SKIP 0
TYPE task1
L1 WEIGHT 1.0
LAB SMOOTH 0
Transferring  p1.0.layers.0.0.weight  to  perception.0.layers.0.0.weight
Transferring  p1.0.layers.0.0.bias  to  perception.0.layers.0.0.bias
Transferring  p1.0.layers.0.1.weight  to  perception.0.layers.0.1.weight
Transferring  p1.0.layers.0.1.bias  to  perception.0.layers.0.1.bias
Transferring  p1.0.layers.0.1.running_mean  to  perception.0.layers.0.1.running_mean
Transferring  p1.0.layers.0.1.running_var  to  perception.0.layers.0.1.running_var
Transferring  p1.0.layers.1.0.weight  to  perception.0.layers.1.0.weight
Transferring  p1.0.layers.1.0.bias  to  perception.0.layers.1.0.bias
Transferring  p1.0.layers.1.1.weight  to  perception.0.layers.1.1.weight
Transferring  p1.0.layers.1.1.bias  to  perception.0.layers.1.1.bias
Transferring  p1.0.layers.1.1.running_mean  to  perception.0.layers.1.1.running_mean
Transferring  p1.0.layers.1.1.running_var  to  perception.0.layers.1.1.running_var
Transferring  p1.0.layers.2.0.weight  to  perception.0.layers.2.0.weight
Transferring  p1.0.layers.2.0.bias  to  perception.0.layers.2.0.bias
Transferring  p1.0.layers.2.1.weight  to  perception.0.layers.2.1.weight
Transferring  p1.0.layers.2.1.bias  to  perception.0.layers.2.1.bias
Transferring  p1.0.layers.2.1.running_mean  to  perception.0.layers.2.1.running_mean
Transferring  p1.0.layers.2.1.running_var  to  perception.0.layers.2.1.running_var
Transferring  p2.0.layers.0.0.weight  to  perception.0.layers.3.0.weight
Transferring  p2.0.layers.0.0.bias  to  perception.0.layers.3.0.bias
Transferring  p2.0.layers.0.1.weight  to  perception.0.layers.3.1.weight
Transferring  p2.0.layers.0.1.bias  to  perception.0.layers.3.1.bias
Transferring  p2.0.layers.0.1.running_mean  to  perception.0.layers.3.1.running_mean
Transferring  p2.0.layers.0.1.running_var  to  perception.0.layers.3.1.running_var
Transferring  p2.0.layers.1.0.weight  to  perception.0.layers.4.0.weight
Transferring  p2.0.layers.1.0.bias  to  perception.0.layers.4.0.bias
Transferring  p2.0.layers.1.1.weight  to  perception.0.layers.4.1.weight
Transferring  p2.0.layers.1.1.bias  to  perception.0.layers.4.1.bias
Transferring  p2.0.layers.1.1.running_mean  to  perception.0.layers.4.1.running_mean
Transferring  p2.0.layers.1.1.running_var  to  perception.0.layers.4.1.running_var
Transferring  p3.0.layers.0.0.weight  to  perception.0.layers.5.0.weight
Transferring  p3.0.layers.0.0.bias  to  perception.0.layers.5.0.bias
Transferring  p3.0.layers.0.1.weight  to  perception.0.layers.5.1.weight
Transferring  p3.0.layers.0.1.bias  to  perception.0.layers.5.1.bias
Transferring  p3.0.layers.0.1.running_mean  to  perception.0.layers.5.1.running_mean
Transferring  p3.0.layers.0.1.running_var  to  perception.0.layers.5.1.running_var
Transferring  p3.0.layers.1.0.weight  to  perception.0.layers.6.0.weight
Transferring  p3.0.layers.1.0.bias  to  perception.0.layers.6.0.bias
Transferring  p3.0.layers.1.1.weight  to  perception.0.layers.6.1.weight
Transferring  p3.0.layers.1.1.bias  to  perception.0.layers.6.1.bias
Transferring  p3.0.layers.1.1.running_mean  to  perception.0.layers.6.1.running_mean
Transferring  p3.0.layers.1.1.running_var  to  perception.0.layers.6.1.running_var
Transferring  perception_bottom.0.layers.0.0.weight  to  perception.0.layers.7.0.weight
Transferring  perception_bottom.0.layers.0.0.bias  to  perception.0.layers.7.0.bias
Transferring  perception_bottom.0.layers.0.1.weight  to  perception.0.layers.7.1.weight
Transferring  perception_bottom.0.layers.0.1.bias  to  perception.0.layers.7.1.bias
Transferring  perception_bottom.0.layers.0.1.running_mean  to  perception.0.layers.7.1.running_mean
Transferring  perception_bottom.0.layers.0.1.running_var  to  perception.0.layers.7.1.running_var
Transferring  perception_bottom.1.layers.0.0.weight  to  perception.1.layers.0.0.weight
Transferring  perception_bottom.1.layers.0.0.bias  to  perception.1.layers.0.0.bias
Transferring  perception_bottom.1.layers.1.0.weight  to  perception.1.layers.1.0.weight
Transferring  perception_bottom.1.layers.1.0.bias  to  perception.1.layers.1.0.bias
Transferring  measurements.layers.0.0.weight  to  measurements.layers.0.0.weight
Transferring  measurements.layers.0.0.bias  to  measurements.layers.0.0.bias
Transferring  measurements.layers.1.0.weight  to  measurements.layers.1.0.weight
Transferring  measurements.layers.1.0.bias  to  measurements.layers.1.0.bias
Transferring  join.after_process.layers.0.0.weight  to  join.after_process.layers.0.0.weight
Transferring  join.after_process.layers.0.0.bias  to  join.after_process.layers.0.0.bias
Transferring  speed_branch.layers.0.0.weight  to  speed_branch.layers.0.0.weight
Transferring  speed_branch.layers.0.0.bias  to  speed_branch.layers.0.0.bias
Transferring  speed_branch.layers.1.0.weight  to  speed_branch.layers.1.0.weight
Transferring  speed_branch.layers.1.0.bias  to  speed_branch.layers.1.0.bias
Transferring  speed_branch.layers.2.0.weight  to  speed_branch.layers.2.0.weight
Transferring  speed_branch.layers.2.0.bias  to  speed_branch.layers.2.0.bias
No Transfer of  branch.layers.0.0.weight  to  branches.branched_modules.0.layers.0.0.weight
No Transfer of  branch.layers.0.0.bias  to  branches.branched_modules.0.layers.0.0.bias
No Transfer of  branch.layers.1.0.weight  to  branches.branched_modules.0.layers.1.0.weight
No Transfer of  branch.layers.1.0.bias  to  branches.branched_modules.0.layers.1.0.bias
No Transfer of  branch.layers.2.0.weight  to  branches.branched_modules.0.layers.2.0.weight
No Transfer of  branch.layers.2.0.bias  to  branches.branched_modules.0.layers.2.0.bias
initialize network with normal
initialize network with normal
_netD(
  (model): Sequential(
    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 0))
    (1): LeakyReLU(negative_slope=0.2, inplace)
    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 0))
    (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (4): LeakyReLU(negative_slope=0.2, inplace)
    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 0))
    (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (7): LeakyReLU(negative_slope=0.2, inplace)
    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 0))
    (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (10): LeakyReLU(negative_slope=0.2, inplace)
    (11): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 0))
    (12): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (13): LeakyReLU(negative_slope=0.2, inplace)
    (14): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 0))
  )
)
_netF(
  (p1): Sequential(
    (0): Conv(
      (layers): Sequential(
        (0): Sequential(
          (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(2, 2))
          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Dropout2d(p=0.2)
          (3): ReLU(inplace)
        )
        (1): Sequential(
          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Dropout2d(p=0.4)
          (3): ReLU(inplace)
        )
        (2): Sequential(
          (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2))
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Dropout2d(p=0.4)
          (3): ReLU(inplace)
        )
      )
    )
  )
  (p2): Sequential(
    (0): Conv(
      (layers): Sequential(
        (0): Sequential(
          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Dropout2d(p=0.4)
          (3): ReLU(inplace)
        )
        (1): Sequential(
          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2))
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Dropout2d(p=0.4)
          (3): ReLU(inplace)
        )
      )
    )
  )
  (p3): Sequential(
    (0): Conv(
      (layers): Sequential(
        (0): Sequential(
          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Dropout2d(p=0.4)
          (3): ReLU(inplace)
        )
        (1): Sequential(
          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Dropout2d(p=0.4)
          (3): ReLU(inplace)
        )
      )
    )
  )
  (perception_bottom): Sequential(
    (0): Conv(
      (layers): Sequential(
        (0): Sequential(
          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Dropout2d(p=0.4)
          (3): ReLU(inplace)
        )
      )
    )
    (1): FC(
      (layers): Sequential(
        (0): Sequential(
          (0): Linear(in_features=8192, out_features=512, bias=True)
          (1): Dropout2d(p=0.5)
          (2): ReLU(inplace)
        )
        (1): Sequential(
          (0): Linear(in_features=512, out_features=512, bias=True)
          (1): Dropout2d(p=0.5)
          (2): ReLU(inplace)
        )
      )
    )
  )
  (measurements): FC(
    (layers): Sequential(
      (0): Sequential(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Dropout2d(p=0.5)
        (2): ReLU(inplace)
      )
      (1): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): Dropout2d(p=0.5)
        (2): ReLU(inplace)
      )
    )
  )
  (join): Join(
    (after_process): FC(
      (layers): Sequential(
        (0): Sequential(
          (0): Linear(in_features=640, out_features=512, bias=True)
          (1): Dropout2d(p=0.5)
          (2): ReLU(inplace)
        )
      )
    )
  )
  (speed_branch): FC(
    (layers): Sequential(
      (0): Sequential(
        (0): Linear(in_features=512, out_features=256, bias=True)
        (1): Dropout2d(p=0.5)
        (2): ReLU(inplace)
      )
      (1): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Dropout2d(p=0.5)
        (2): ReLU(inplace)
      )
      (2): Sequential(
        (0): Linear(in_features=256, out_features=1, bias=True)
        (1): Dropout2d(p=0.0)
        (2): ReLU(inplace)
      )
    )
  )
  (branch): FC(
    (layers): Sequential(
      (0): Sequential(
        (0): Linear(in_features=512, out_features=256, bias=True)
        (1): Dropout2d(p=0.5)
        (2): ReLU(inplace)
      )
      (1): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Dropout2d(p=0.5)
        (2): ReLU(inplace)
      )
      (2): Sequential(
        (0): Linear(in_features=256, out_features=3, bias=True)
        (1): Dropout2d(p=0.0)
      )
    )
  )
)
_netG(
  (stage1_upsample): Sequential(
    (0): ConvTranspose2d(256, 256, kernel_size=(7, 7), stride=(1, 1))
    (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (2): ReLU(inplace)
    (3): ResnetBlock(
      (conv_layer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dropout): Dropout(p=0.5)
      (activation): ReLU(inplace)
      (normalization_layer): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    )
    (4): ResnetBlock(
      (conv_layer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dropout): Dropout(p=0.5)
      (activation): ReLU(inplace)
      (normalization_layer): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    )
    (5): ResnetBlock(
      (conv_layer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dropout): Dropout(p=0.5)
      (activation): ReLU(inplace)
      (normalization_layer): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    )
  )
  (stage2_upsample): Sequential(
    (0): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (2): ReLU(inplace)
    (3): ResnetBlock(
      (conv_layer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dropout): Dropout(p=0.5)
      (activation): ReLU(inplace)
      (normalization_layer): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    )
    (4): ResnetBlock(
      (conv_layer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dropout): Dropout(p=0.5)
      (activation): ReLU(inplace)
      (normalization_layer): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    )
    (5): ResnetBlock(
      (conv_layer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dropout): Dropout(p=0.5)
      (activation): ReLU(inplace)
      (normalization_layer): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    )
  )
  (stage3_upsample): Sequential(
    (0): ConvTranspose2d(256, 128, kernel_size=(5, 5), stride=(2, 2))
    (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (2): ReLU(inplace)
    (3): ResnetBlock(
      (conv_layer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dropout): Dropout(p=0.5)
      (activation): ReLU(inplace)
      (normalization_layer): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    )
    (4): ResnetBlock(
      (conv_layer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dropout): Dropout(p=0.5)
      (activation): ReLU(inplace)
      (normalization_layer): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    )
  )
  (stage4_upsample): Sequential(
    (0): ConvTranspose2d(128, 3, kernel_size=(8, 8), stride=(2, 2))
    (1): Sigmoid()
  )
)
Branch Outputs::: tensor([ 0.1833,  0.3528,  0.6250], device='cuda:0')
----------------
Loss d tensor(1046.1940, device='cuda:0')
LossD 1046.1939697265625 LossG [100.0] BestLossD 1046.1939697265625 BestLossG 100.0 LossF tensor([ 100.]) BestLossF 100.0 Iteration 0 Best Loss Iteration G 0 Best Loss Iteration F 0
Branch Outputs::: tensor([-2.9808, -0.2830, -0.6505], device='cuda:0')
Loss d tensor(732.0518, device='cuda:0')
LossD 732.0518188476562 LossG [100.0] BestLossD 732.0518188476562 BestLossG 100.0 LossF tensor([ 100.]) BestLossF 100.0 Iteration 1 Best Loss Iteration G 0 Best Loss Iteration F 0
Branch Outputs::: tensor([-0.2415,  0.8251,  0.2492], device='cuda:0')
Loss d tensor(423.6230, device='cuda:0')
LossD 423.6229553222656 LossG [100.0] BestLossD 423.6229553222656 BestLossG 100.0 LossF tensor([ 100.]) BestLossF 100.0 Iteration 2 Best Loss Iteration G 0 Best Loss Iteration F 0
Branch Outputs::: tensor([ 0.3776,  0.7372,  0.3293], device='cuda:0')
Loss d tensor(270.5539, device='cuda:0')
LossD 270.5538635253906 LossG [100.0] BestLossD 270.5538635253906 BestLossG 100.0 LossF tensor([ 100.]) BestLossF 100.0 Iteration 3 Best Loss Iteration G 0 Best Loss Iteration F 0
Branch Outputs::: tensor([-0.3162, -1.6640, -1.2535], device='cuda:0')
Loss d tensor(173.2757, device='cuda:0')
