steer shape (50000,)
labels shape  (50000,)
Configurations of  all_da
GANMODEL_NAME LSDcontrol_task_2d
LOSS_FUNCTION WGANmix
LR_G, LR_D, LR 0.0002 0.0002 0.0002
SKIP 0
TYPE task
L1 WEIGHT 1.0
TASK ADV WEIGHT 0.1
LAB SMOOTH 1
Loading IL
70 88
Transferring  p1.0.layers.0.0.weight  to  perception.0.layers.0.0.weight
Transferring  p1.0.layers.0.0.bias  to  perception.0.layers.0.0.bias
Transferring  p1.0.layers.0.1.weight  to  perception.0.layers.0.1.weight
Transferring  p1.0.layers.0.1.bias  to  perception.0.layers.0.1.bias
Transferring  p1.0.layers.0.1.running_mean  to  perception.0.layers.0.1.running_mean
Transferring  p1.0.layers.0.1.running_var  to  perception.0.layers.0.1.running_var
Transferring  p1.0.layers.1.0.weight  to  perception.0.layers.1.0.weight
Transferring  p1.0.layers.1.0.bias  to  perception.0.layers.1.0.bias
Transferring  p1.0.layers.1.1.weight  to  perception.0.layers.1.1.weight
Transferring  p1.0.layers.1.1.bias  to  perception.0.layers.1.1.bias
Transferring  p1.0.layers.1.1.running_mean  to  perception.0.layers.1.1.running_mean
Transferring  p1.0.layers.1.1.running_var  to  perception.0.layers.1.1.running_var
Transferring  p1.0.layers.2.0.weight  to  perception.0.layers.2.0.weight
Transferring  p1.0.layers.2.0.bias  to  perception.0.layers.2.0.bias
Transferring  p1.0.layers.2.1.weight  to  perception.0.layers.2.1.weight
Transferring  p1.0.layers.2.1.bias  to  perception.0.layers.2.1.bias
Transferring  p1.0.layers.2.1.running_mean  to  perception.0.layers.2.1.running_mean
Transferring  p1.0.layers.2.1.running_var  to  perception.0.layers.2.1.running_var
Transferring  p2.0.layers.0.0.weight  to  perception.0.layers.3.0.weight
Transferring  p2.0.layers.0.0.bias  to  perception.0.layers.3.0.bias
Transferring  p2.0.layers.0.1.weight  to  perception.0.layers.3.1.weight
Transferring  p2.0.layers.0.1.bias  to  perception.0.layers.3.1.bias
Transferring  p2.0.layers.0.1.running_mean  to  perception.0.layers.3.1.running_mean
Transferring  p2.0.layers.0.1.running_var  to  perception.0.layers.3.1.running_var
Transferring  p2.0.layers.1.0.weight  to  perception.0.layers.4.0.weight
Transferring  p2.0.layers.1.0.bias  to  perception.0.layers.4.0.bias
Transferring  p2.0.layers.1.1.weight  to  perception.0.layers.4.1.weight
Transferring  p2.0.layers.1.1.bias  to  perception.0.layers.4.1.bias
Transferring  p2.0.layers.1.1.running_mean  to  perception.0.layers.4.1.running_mean
Transferring  p2.0.layers.1.1.running_var  to  perception.0.layers.4.1.running_var
Transferring  p3.0.layers.0.0.weight  to  perception.0.layers.5.0.weight
Transferring  p3.0.layers.0.0.bias  to  perception.0.layers.5.0.bias
Transferring  p3.0.layers.0.1.weight  to  perception.0.layers.5.1.weight
Transferring  p3.0.layers.0.1.bias  to  perception.0.layers.5.1.bias
Transferring  p3.0.layers.0.1.running_mean  to  perception.0.layers.5.1.running_mean
Transferring  p3.0.layers.0.1.running_var  to  perception.0.layers.5.1.running_var
Transferring  p3.0.layers.1.0.weight  to  perception.0.layers.6.0.weight
Transferring  p3.0.layers.1.0.bias  to  perception.0.layers.6.0.bias
Transferring  p3.0.layers.1.1.weight  to  perception.0.layers.6.1.weight
Transferring  p3.0.layers.1.1.bias  to  perception.0.layers.6.1.bias
Transferring  p3.0.layers.1.1.running_mean  to  perception.0.layers.6.1.running_mean
Transferring  p3.0.layers.1.1.running_var  to  perception.0.layers.6.1.running_var
Transferring  perception_bottom.0.layers.0.0.weight  to  perception.0.layers.7.0.weight
Transferring  perception_bottom.0.layers.0.0.bias  to  perception.0.layers.7.0.bias
Transferring  perception_bottom.0.layers.0.1.weight  to  perception.0.layers.7.1.weight
Transferring  perception_bottom.0.layers.0.1.bias  to  perception.0.layers.7.1.bias
Transferring  perception_bottom.0.layers.0.1.running_mean  to  perception.0.layers.7.1.running_mean
Transferring  perception_bottom.0.layers.0.1.running_var  to  perception.0.layers.7.1.running_var
Transferring  perception_bottom.1.layers.0.0.weight  to  perception.1.layers.0.0.weight
Transferring  perception_bottom.1.layers.0.0.bias  to  perception.1.layers.0.0.bias
Transferring  perception_bottom.1.layers.1.0.weight  to  perception.1.layers.1.0.weight
Transferring  perception_bottom.1.layers.1.0.bias  to  perception.1.layers.1.0.bias
Transferring  measurements.layers.0.0.weight  to  measurements.layers.0.0.weight
Transferring  measurements.layers.0.0.bias  to  measurements.layers.0.0.bias
Transferring  measurements.layers.1.0.weight  to  measurements.layers.1.0.weight
Transferring  measurements.layers.1.0.bias  to  measurements.layers.1.0.bias
Transferring  join.after_process.layers.0.0.weight  to  join.after_process.layers.0.0.weight
Transferring  join.after_process.layers.0.0.bias  to  join.after_process.layers.0.0.bias
Transferring  speed_branch.layers.0.0.weight  to  speed_branch.layers.0.0.weight
Transferring  speed_branch.layers.0.0.bias  to  speed_branch.layers.0.0.bias
Transferring  speed_branch.layers.1.0.weight  to  speed_branch.layers.1.0.weight
Transferring  speed_branch.layers.1.0.bias  to  speed_branch.layers.1.0.bias
Transferring  speed_branch.layers.2.0.weight  to  speed_branch.layers.2.0.weight
Transferring  speed_branch.layers.2.0.bias  to  speed_branch.layers.2.0.bias
Transferring  branch.layers.0.0.weight  to  branches.branched_modules.0.layers.0.0.weight
Transferring  branch.layers.0.0.bias  to  branches.branched_modules.0.layers.0.0.bias
Transferring  branch.layers.1.0.weight  to  branches.branched_modules.0.layers.1.0.weight
Transferring  branch.layers.1.0.bias  to  branches.branched_modules.0.layers.1.0.bias
Transferring  branch.layers.2.0.weight  to  branches.branched_modules.0.layers.2.0.weight
Transferring  branch.layers.2.0.bias  to  branches.branched_modules.0.layers.2.0.bias
IL Model Loaded!
Loading Decoder
24 24
Transferring  stage1_upsample.0.weight  to  stage1_upsample.0.weight
Transferring  stage1_upsample.0.bias  to  stage1_upsample.0.bias
Transferring  stage1_upsample.3.conv_layer.weight  to  stage1_upsample.3.conv_layer.weight
Transferring  stage1_upsample.3.conv_layer.bias  to  stage1_upsample.3.conv_layer.bias
Transferring  stage1_upsample.4.conv_layer.weight  to  stage1_upsample.4.conv_layer.weight
Transferring  stage1_upsample.4.conv_layer.bias  to  stage1_upsample.4.conv_layer.bias
Transferring  stage1_upsample.5.conv_layer.weight  to  stage1_upsample.5.conv_layer.weight
Transferring  stage1_upsample.5.conv_layer.bias  to  stage1_upsample.5.conv_layer.bias
Transferring  stage2_upsample.0.weight  to  stage2_upsample.0.weight
Transferring  stage2_upsample.0.bias  to  stage2_upsample.0.bias
Transferring  stage2_upsample.3.conv_layer.weight  to  stage2_upsample.3.conv_layer.weight
Transferring  stage2_upsample.3.conv_layer.bias  to  stage2_upsample.3.conv_layer.bias
Transferring  stage2_upsample.4.conv_layer.weight  to  stage2_upsample.4.conv_layer.weight
Transferring  stage2_upsample.4.conv_layer.bias  to  stage2_upsample.4.conv_layer.bias
Transferring  stage2_upsample.5.conv_layer.weight  to  stage2_upsample.5.conv_layer.weight
Transferring  stage2_upsample.5.conv_layer.bias  to  stage2_upsample.5.conv_layer.bias
Transferring  stage3_upsample.0.weight  to  stage3_upsample.0.weight
Transferring  stage3_upsample.0.bias  to  stage3_upsample.0.bias
Transferring  stage3_upsample.3.conv_layer.weight  to  stage3_upsample.3.conv_layer.weight
Transferring  stage3_upsample.3.conv_layer.bias  to  stage3_upsample.3.conv_layer.bias
Transferring  stage3_upsample.4.conv_layer.weight  to  stage3_upsample.4.conv_layer.weight
Transferring  stage3_upsample.4.conv_layer.bias  to  stage3_upsample.4.conv_layer.bias
Transferring  stage4_upsample.0.weight  to  stage4_upsample.0.weight
Transferring  stage4_upsample.0.bias  to  stage4_upsample.0.bias
Decoder Model Loaded!
initialize network with normal
initialize network with normal
_netD_bin(
  (main_model): Sequential(
    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 0))
    (1): LeakyReLU(negative_slope=0.2, inplace)
    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 0))
    (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (4): LeakyReLU(negative_slope=0.2, inplace)
    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 0))
    (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (7): LeakyReLU(negative_slope=0.2, inplace)
    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 0))
    (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (10): LeakyReLU(negative_slope=0.2, inplace)
  )
  (bin_model): Sequential(
    (0): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 0))
    (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (2): LeakyReLU(negative_slope=0.2, inplace)
    (3): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 0))
  )
)
_netD_aux(
  (main_model): Sequential(
    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 0))
    (1): LeakyReLU(negative_slope=0.2, inplace)
    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 0))
    (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (4): LeakyReLU(negative_slope=0.2, inplace)
    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 0))
    (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (7): LeakyReLU(negative_slope=0.2, inplace)
    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 0))
    (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (10): LeakyReLU(negative_slope=0.2, inplace)
  )
  (aux_model): Sequential(
    (0): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (2): LeakyReLU(negative_slope=0.2, inplace)
    (3): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))
  )
)
_netF(
  (p1): Sequential(
    (0): Conv(
      (layers): Sequential(
        (0): Sequential(
          (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(2, 2))
          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Dropout2d(p=0.2)
          (3): ReLU(inplace)
        )
        (1): Sequential(
          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Dropout2d(p=0.4)
          (3): ReLU(inplace)
        )
        (2): Sequential(
          (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2))
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Dropout2d(p=0.4)
          (3): ReLU(inplace)
        )
      )
    )
  )
  (p2): Sequential(
    (0): Conv(
      (layers): Sequential(
        (0): Sequential(
          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Dropout2d(p=0.4)
          (3): ReLU(inplace)
        )
        (1): Sequential(
          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2))
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Dropout2d(p=0.4)
          (3): ReLU(inplace)
        )
      )
    )
  )
  (p3): Sequential(
    (0): Conv(
      (layers): Sequential(
        (0): Sequential(
          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Dropout2d(p=0.4)
          (3): ReLU(inplace)
        )
        (1): Sequential(
          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Dropout2d(p=0.4)
          (3): ReLU(inplace)
        )
      )
    )
  )
  (perception_bottom): Sequential(
    (0): Conv(
      (layers): Sequential(
        (0): Sequential(
          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Dropout2d(p=0.4)
          (3): ReLU(inplace)
        )
      )
    )
    (1): FC(
      (layers): Sequential(
        (0): Sequential(
          (0): Linear(in_features=8192, out_features=512, bias=True)
          (1): Dropout2d(p=0.5)
          (2): ReLU(inplace)
        )
        (1): Sequential(
          (0): Linear(in_features=512, out_features=512, bias=True)
          (1): Dropout2d(p=0.5)
          (2): ReLU(inplace)
        )
      )
    )
  )
  (measurements): FC(
    (layers): Sequential(
      (0): Sequential(
        (0): Linear(in_features=1, out_features=128, bias=True)
        (1): Dropout2d(p=0.5)
        (2): ReLU(inplace)
      )
      (1): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): Dropout2d(p=0.5)
        (2): ReLU(inplace)
      )
    )
  )
  (join): Join(
    (after_process): FC(
      (layers): Sequential(
        (0): Sequential(
          (0): Linear(in_features=640, out_features=512, bias=True)
          (1): Dropout2d(p=0.5)
          (2): ReLU(inplace)
        )
      )
    )
  )
  (speed_branch): FC(
    (layers): Sequential(
      (0): Sequential(
        (0): Linear(in_features=512, out_features=256, bias=True)
        (1): Dropout2d(p=0.5)
        (2): ReLU(inplace)
      )
      (1): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Dropout2d(p=0.5)
        (2): ReLU(inplace)
      )
      (2): Sequential(
        (0): Linear(in_features=256, out_features=1, bias=True)
        (1): Dropout2d(p=0.0)
        (2): ReLU(inplace)
      )
    )
  )
  (branch): FC(
    (layers): Sequential(
      (0): Sequential(
        (0): Linear(in_features=512, out_features=256, bias=True)
        (1): Dropout2d(p=0.5)
        (2): ReLU(inplace)
      )
      (1): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Dropout2d(p=0.5)
        (2): ReLU(inplace)
      )
      (2): Sequential(
        (0): Linear(in_features=256, out_features=3, bias=True)
        (1): Dropout2d(p=0.0)
      )
    )
  )
)
_netG(
  (stage1_upsample): Sequential(
    (0): ConvTranspose2d(256, 256, kernel_size=(7, 7), stride=(1, 1))
    (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (2): ReLU(inplace)
    (3): ResnetBlock(
      (conv_layer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dropout): Dropout(p=0.5)
      (activation): ReLU(inplace)
      (normalization_layer): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    )
    (4): ResnetBlock(
      (conv_layer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dropout): Dropout(p=0.5)
      (activation): ReLU(inplace)
      (normalization_layer): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    )
    (5): ResnetBlock(
      (conv_layer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dropout): Dropout(p=0.5)
      (activation): ReLU(inplace)
      (normalization_layer): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    )
  )
  (stage2_upsample): Sequential(
    (0): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (2): ReLU(inplace)
    (3): ResnetBlock(
      (conv_layer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dropout): Dropout(p=0.5)
      (activation): ReLU(inplace)
      (normalization_layer): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    )
    (4): ResnetBlock(
      (conv_layer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dropout): Dropout(p=0.5)
      (activation): ReLU(inplace)
      (normalization_layer): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    )
    (5): ResnetBlock(
      (conv_layer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dropout): Dropout(p=0.5)
      (activation): ReLU(inplace)
      (normalization_layer): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    )
  )
  (stage3_upsample): Sequential(
    (0): ConvTranspose2d(256, 128, kernel_size=(5, 5), stride=(2, 2))
    (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (2): ReLU(inplace)
    (3): ResnetBlock(
      (conv_layer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dropout): Dropout(p=0.5)
      (activation): ReLU(inplace)
      (normalization_layer): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    )
    (4): ResnetBlock(
      (conv_layer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (dropout): Dropout(p=0.5)
      (activation): ReLU(inplace)
      (normalization_layer): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    )
  )
  (stage4_upsample): Sequential(
    (0): ConvTranspose2d(128, 3, kernel_size=(8, 8), stride=(2, 2))
    (1): Sigmoid()
  )
)
Using cross entropy!
----------------
Discriminator aux label size HERE torch.Size([30, 4])
tensor([[ 0.0339, -1.5005,  0.1801,  0.4259],
        [-2.3037, -0.6857,  0.1769,  0.4960],
        [-1.0861, -0.8695,  0.0670,  0.1905],
        [-0.0349,  0.0046,  0.5320,  0.6413],
        [-0.9173,  0.1085, -1.0299,  0.0250],
        [-0.7515, -0.1782,  0.5126,  0.5011],
        [-1.3604,  0.1239,  0.0237,  0.5567],
        [-0.5097, -1.1703, -0.7647,  0.1093],
        [-0.9020,  0.7541, -0.2928,  0.7951],
        [ 0.3778,  0.3636,  0.8328,  0.2597],
        [-0.7675,  0.2104, -0.8983,  0.0015],
        [-0.3242, -1.1891, -0.8530,  1.4669],
        [ 0.3470,  0.2660,  0.0298, -1.2040],
        [-1.4718,  0.0127,  1.0164,  0.9510],
        [-0.5525,  0.7715, -0.3043,  0.2518],
        [-1.2265,  0.7953, -0.2800,  0.2879],
        [-1.9074, -0.2204,  0.3010,  0.6074],
        [-0.3718, -0.1018, -2.2139, -0.0803],
        [-0.5737,  0.0172, -1.7804,  0.8996],
        [-0.0503,  0.5242, -0.3941, -1.1235],
        [-0.3695, -0.8128, -0.2301,  0.6144],
        [-0.8485,  0.0157,  0.9850, -0.1579],
        [ 0.7188, -0.2977, -1.4524,  0.4921],
        [ 0.9442, -1.0988, -1.0827,  0.4323],
        [-1.3843, -0.5109, -0.5802,  0.5491],
        [-0.5961, -0.6477,  0.2092, -0.2521],
        [-0.7541,  0.1014,  0.2607, -0.3333],
        [-0.8239, -0.8706, -0.5213, -0.0166],
        [-0.3186,  1.1683, -0.6951,  0.8490],
        [-0.8610, -0.0147, -0.0698,  1.3836]], device='cuda:0') tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
         0,  0], device='cuda:0')
Some discriminator outputs::  tensor([ 0.0339, -1.5005,  0.1801,  0.4259], device='cuda:0') tensor([-0.7005, -0.9321, -0.1650,  0.8173], device='cuda:0') tensor([ 0.0473, -0.1431,  0.2807,  0.5559], device='cuda:0') tensor([ 0.0352, -0.2283,  0.9749, -0.1388], device='cuda:0')
Discriminator aux label size HERE torch.Size([30, 4])
tensor([[ 1.5486,  1.6279, -0.6380, -0.4583],
        [ 1.3923,  0.8733, -0.8227,  0.1614],
        [ 1.5406,  2.8599,  0.1340, -1.7050],
        [ 0.7139,  1.5350, -1.3007,  0.5706],
        [ 1.3685,  1.0937,  0.5916, -1.1900],
        [ 1.2897,  2.2413, -1.4750, -1.4707],
        [ 0.8413,  1.7771,  0.4726, -1.5701],
        [ 1.5491,  3.0844,  0.2357, -1.9010],
        [ 0.7863, -0.6567,  0.9295, -0.5822],
        [ 1.5046,  2.8001, -0.2021, -0.6832],
        [-0.5506,  0.9931, -1.2931, -2.0419],
        [ 0.4568,  1.8458, -1.7476, -2.1780],
        [ 2.2824,  1.6755, -1.2658, -1.2891],
        [ 0.9216,  1.5132,  1.9538, -2.6774],
        [ 2.0589,  2.9549,  0.6206, -1.6825],
        [ 2.0501,  1.6083, -0.0920, -1.8243],
        [ 1.5627,  0.8867,  2.1060, -2.7074],
        [ 1.8296,  3.0515,  1.1714, -0.9166],
        [ 2.9545,  2.2502, -0.3709, -1.9405],
        [ 1.1054,  1.3144, -2.0652, -1.6488],
        [ 1.2398,  1.9915,  0.6605,  1.0194],
        [ 1.0146,  1.1898, -0.7575, -0.4941],
        [-0.2268,  1.4279, -0.8931, -1.1949],
        [ 0.0854,  0.5896, -2.3815, -1.9551],
        [ 1.2934,  0.7131, -0.7344, -2.2639],
        [ 2.5727, -0.5021, -1.0499, -0.5302],
        [ 0.5570, -0.1429, -0.4033, -0.6436],
        [ 1.5806,  1.3451,  0.7339, -1.6974],
        [ 1.3726,  2.0306, -0.2003, -1.7032],
        [ 2.7996,  1.8755, -0.1332, -1.2662]], device='cuda:0') tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
         0,  0], device='cuda:0')
Some discriminator outputs::  tensor([ 1.5486,  1.6279, -0.6380, -0.4583], device='cuda:0') tensor([ 1.8683,  1.4885, -1.7442, -0.7421], device='cuda:0') tensor([ 1.1417,  1.4282,  0.8063, -1.2283], device='cuda:0') tensor([ 0.9936, -0.5978,  0.4310,  1.0199], device='cuda:0')
Discriminator aux label size HERE torch.Size([30, 4])
tensor([[ 1.9872,  0.3232,  1.5403, -0.9785],
        [ 2.0057,  0.0240,  0.4541, -0.6409],
        [ 0.5392,  1.5978,  3.0180, -1.3572],
        [ 2.6980,  1.2619,  1.2205, -0.4534],
        [ 1.6274, -1.3450,  3.0231,  1.1694],
        [-1.6211,  0.3524,  1.8672, -0.8374],
        [ 1.2207,  3.3363, -0.1807, -1.3303],
        [ 1.8917,  0.8998,  1.4040, -1.1109],
        [-0.4839,  1.2978,  1.3049, -0.2251],
        [ 0.9527,  2.2447,  2.8277, -0.6487],
        [-0.1217, -0.2454, -1.1523, -0.5083],
        [ 1.5987,  2.2890,  3.3985,  0.0832],
        [-0.0332,  0.8905, -1.7395,  0.4162],
        [ 1.6440,  2.0772, -0.9436, -1.3578],
        [ 2.0666,  1.2181,  2.6442,  0.2318],
        [ 1.1118,  0.5996, -0.5019, -1.5632],
        [-0.5513, -1.6156,  0.9920,  0.8740],
        [ 1.3593, -0.1830, -0.6942, -1.2912],
        [ 1.1747,  0.7913,  1.3866,  1.5328],
        [ 1.7773, -0.0641,  0.4317, -0.7668],
        [-1.0132,  1.0501,  1.8029, -0.3661],
        [ 2.3133,  0.8723,  0.4006, -1.0121],
        [-1.0758, -0.8065,  1.1109, -0.5102],
        [ 2.9106,  1.8113,  0.6861, -1.7661],
        [ 0.9666,  0.1811, -0.3155, -1.4952],
        [ 0.9329,  2.1511, -0.0231, -0.7600],
        [ 1.5091,  0.3698,  1.9656,  0.3878],
        [ 1.0484,  1.6322,  1.3135, -0.6926],
        [ 1.1566,  1.4743,  2.4546, -1.3795],
        [-0.5634, -0.2479,  0.2416, -0.7913]], device='cuda:0') tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
         0,  0], device='cuda:0')
Some discriminator outputs::  tensor([ 1.9872,  0.3232,  1.5403, -0.9785], device='cuda:0') tensor([ 0.4965,  1.3241,  1.9079, -1.2839], device='cuda:0') tensor([ 0.1843, -0.5093,  3.9987,  0.3673], device='cuda:0') tensor([-0.5837, -1.7976,  0.7774,  3.7035], device='cuda:0')
Discriminator aux label size HERE torch.Size([30, 4])
tensor([[ 0.4602,  0.8733,  0.4157, -0.0205],
        [ 3.0819,  0.9707, -1.3989, -2.3082],
        [ 1.6628,  1.7754,  1.0024, -1.1128],
        [ 3.0630,  1.1645, -1.1343, -1.4983],
        [ 2.9787,  2.6144,  0.0865, -2.5325],
        [ 0.2183,  0.5221, -0.4387,  1.0929],
        [ 2.2804,  2.8278,  0.3595, -0.9560],
        [ 0.2598,  0.9352,  1.5044, -0.1327],
        [ 1.6392,  0.9593, -0.6992, -2.0608],
        [ 0.4629,  2.9435, -1.5198, -2.5290],
        [ 2.8020,  2.1051,  1.2752, -1.7660],
        [ 1.4578,  0.1817, -0.6710, -0.8206],
        [ 0.8790,  1.6864, -1.7270, -2.3912],
        [-0.4526, -0.1282,  1.4621, -1.3714],
        [ 2.1690,  1.9782, -0.7924, -2.7124],
        [-0.5216, -0.5512, -1.7206, -2.3659],
        [ 1.9718,  1.1578,  0.6312, -1.8920],
        [ 0.9391,  3.7438,  0.2513, -1.9984],
        [ 1.1177,  0.1883,  2.5018,  0.0822],
        [ 2.9707,  4.6620,  1.5802, -1.1289],
        [ 3.2685,  1.3237,  1.5182, -1.6645],
        [ 1.9449,  0.6089, -0.3838, -1.1137],
        [-1.2282,  0.3613, -0.8954, -1.5819],
        [ 0.3745,  1.7520, -0.7817, -0.7399],
        [ 0.8809,  1.8091,  1.2686, -0.9727],
        [ 1.0808,  1.1681,  1.1706, -0.5155],
        [ 2.0164,  2.5832,  3.2404, -0.4698],
        [ 0.4192,  0.0525,  1.6995, -0.4243],
        [ 1.4913,  0.1201,  0.4650, -1.2263],
        [ 2.3603,  1.3143, -1.0531, -1.4863]], device='cuda:0') tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
         0,  0], device='cuda:0')
Some discriminator outputs::  tensor([ 0.4602,  0.8733,  0.4157, -0.0205], device='cuda:0') tensor([ 0.6677,  0.7615, -0.8723, -0.8817], device='cuda:0') tensor([ 2.2148,  1.2598,  1.4116, -0.8142], device='cuda:0') tensor([-0.2920, -1.2307, -0.3684,  3.0991], device='cuda:0')
Discriminator aux label size HERE torch.Size([30, 4])
tensor([[ 2.5593,  1.6965,  0.6904, -0.7849],
        [ 1.7214,  4.1819, -0.9938, -4.6068],
        [ 4.1347, -0.5154, -0.0020, -1.5809],
        [ 2.6656,  2.1739,  0.5404, -1.7077],
        [ 1.3451,  0.0442, -2.2975, -0.7280],
        [ 3.2777,  1.7554, -0.4574, -2.8095],
        [ 2.0418,  2.0094,  0.2333, -1.3961],
        [ 1.0290, -0.8967, -0.2129, -1.2119],
        [ 3.2120,  0.3075,  0.6030, -1.3700],
        [ 2.0573,  0.5938, -1.8198, -0.9445],
        [ 1.9233,  1.1921, -1.5324, -1.8160],
        [ 2.1468,  1.4329,  0.5305, -2.4752],
        [-0.0430,  1.7999,  0.0501,  0.0189],
        [ 1.4172,  0.4206,  3.9041, -0.1551],
        [ 1.6783,  2.7013,  2.2159, -0.5244],
        [ 1.6597, -0.0997, -1.0096, -2.2456],
        [ 0.5625, -0.5161, -1.1796, -0.3045],
        [ 2.0420,  1.0179,  0.6059, -1.2863],
        [ 1.8069, -0.1690, -0.2397, -1.7934],
        [ 3.3112,  2.0983,  0.9895, -2.8824],
        [ 2.0155,  1.9789,  0.7711, -1.2236],
        [ 1.9192,  1.7075,  0.1410, -3.4614],
        [-0.0428,  0.4206, -0.2074, -1.0082],
        [ 2.9333,  2.1522,  0.7548, -1.8296],
        [ 2.8697,  0.2502,  1.2381, -1.4119],
        [ 0.1265,  2.1586, -1.4069, -2.3846],
        [ 2.1387, -0.2305, -1.2808, -1.0879],
        [ 1.7362,  1.1407,  0.4255, -1.1506],
        [ 0.1117,  1.3098,  0.9223, -0.3996],
        [ 0.1101,  1.8110,  0.2281, -2.4003]], device='cuda:0') tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
         0,  0], device='cuda:0')
Some discriminator outputs::  tensor([ 2.5593,  1.6965,  0.6904, -0.7849], device='cuda:0') tensor([ 1.9527,  0.5825, -0.1322, -0.7773], device='cuda:0') tensor([ 2.3035,  1.2861,  3.2425, -1.2780], device='cuda:0') tensor([ 0.1444, -0.6918, -0.2808,  2.2132], device='cuda:0')
Discriminator aux label size HERE torch.Size([30, 4])
tensor([[ 2.1520,  1.4073, -1.0169, -1.8201],
        [ 2.9612,  2.5314,  1.0307, -1.7546],
        [ 2.7441,  3.2248, -0.3129, -0.7930],
        [-1.1049,  0.0138,  1.5029,  0.0535],
        [ 2.2631,  2.2104, -0.5708, -2.7446],
        [-0.0216,  0.5911,  1.2872, -0.1863],
        [ 1.6854,  1.7743,  1.3611, -3.1062],
        [ 2.0641,  3.2658, -0.2868, -1.3223],
        [ 2.3495,  2.1656,  0.8026, -1.6549],
        [ 4.7348,  3.7445,  1.0067, -0.9779],
        [ 1.6240,  1.2330,  0.1779, -0.5506],
        [ 3.6874,  2.0665,  0.3485, -2.4034],
        [ 1.9933,  2.0948,  0.1348, -1.9419],
        [ 2.6779,  2.9765,  4.1892, -2.0304],
        [ 2.6555,  2.2833,  3.4920, -1.9892],
        [ 1.3882,  0.9581, -0.6494, -2.5837],
        [ 0.6542,  3.3480, -1.6464, -2.7393],
        [ 1.2707,  2.0723,  0.1808, -1.1294],
        [ 2.2907,  2.4817,  0.6991, -1.1594],
        [ 1.3734,  4.0572, -1.2248, -1.1799],
        [ 2.3820,  2.9134, -1.0329, -1.9937],
        [ 0.0234,  2.6783,  1.8210,  0.2506],
        [ 1.3794,  1.7218,  0.8284, -0.5589],
        [ 4.6178,  2.0389, -2.1861, -2.1875],
        [ 2.0863,  1.2262, -0.4631, -2.0006],
        [ 1.8570,  3.1142,  1.5179, -2.4320],
        [ 0.5957,  1.0912, -1.5290, -0.4449],
        [ 1.5659,  3.0906, -0.7117, -0.3018],
        [ 3.4303,  0.7254,  1.2146, -1.3643],
        [ 3.4445,  2.7637, -0.2527, -0.9028]], device='cuda:0') tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
         0,  0], device='cuda:0')
Some discriminator outputs::  tensor([ 2.1520,  1.4073, -1.0169, -1.8201], device='cuda:0') tensor([ 1.9471,  0.4924, -0.2621, -2.6884], device='cuda:0') tensor([ 2.9113,  0.7518,  3.8454, -0.8519], device='cuda:0') tensor([ 0.1272, -0.7085,  0.4498,  2.3507], device='cuda:0')
Discriminator aux label size HERE torch.Size([30, 4])
tensor([[ 3.7704,  0.7429, -0.2021, -1.1570],
        [ 1.0208,  2.3363, -0.1257, -0.5739],
        [ 0.9680,  2.1151,  0.8218, -0.8439],
        [ 0.6958, -0.9188, -0.1981, -1.4020],
        [ 3.2348,  2.4686, -0.1171,  0.2305],
        [ 2.9669,  3.4153,  0.7719, -3.6118],
        [ 2.6850,  2.1777,  0.5957, -2.2459],
        [ 2.2506,  1.6745,  0.1016, -2.1498],
        [ 1.1146,  1.4161,  2.8580, -0.9749],
        [ 2.8341,  2.2390, -0.1770, -2.6245],
        [ 2.6423,  0.3699, -0.2466, -1.4520],
        [ 3.8216,  0.5862, -0.1275, -0.9819],
        [ 0.5285, -1.9089, -0.1667, -0.0605],
        [ 3.2834,  1.7225,  0.1145, -1.7318],
        [ 1.2284,  1.2844,  0.0048, -0.6142],
        [ 2.3085,  0.8947,  1.0506, -0.5605],
        [ 1.3954,  2.1849,  1.1106, -1.7240],
        [ 1.3230,  2.4323,  1.0525, -1.5419],
        [-0.2510,  2.0783,  2.1095, -1.3869],
        [ 2.3653,  1.5799, -1.1120, -0.9078],
        [ 2.8221,  2.0944,  1.5479, -1.8587],
        [ 1.2943,  0.8957,  0.5575, -1.8169],
        [ 1.2092,  0.0222,  0.8031, -0.9521],
        [-0.1014,  1.2389,  1.2321, -0.1950],
        [ 2.2739,  0.7157,  1.9445, -1.5292],
        [ 2.1053,  1.2435, -1.2431, -1.1141],
        [ 1.9468,  0.9132, -1.2377, -0.7933],
        [ 1.7730,  2.6609,  0.7247, -1.6544],
        [ 1.1323,  1.8536,  0.8349, -3.3517],
        [ 2.5751,  1.9761,  0.4055, -1.1934]], device='cuda:0') tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
         0,  0], device='cuda:0')
Some discriminator outputs::  tensor([ 3.7704,  0.7429, -0.2021, -1.1570], device='cuda:0') tensor([ 2.4195,  3.3424,  0.7172, -1.4605], device='cuda:0') tensor([ 1.8651, -1.0153, -2.0289, -0.2392], device='cuda:0') tensor([-1.4773, -0.5488, -1.8068,  1.1507], device='cuda:0')
Discriminator aux label size HERE torch.Size([30, 4])
tensor([[ 2.3479, -0.0409,  1.6757, -0.5040],
        [-1.0678,  0.5057,  1.5654, -0.5237],
        [-0.6473, -0.1670,  2.5818,  0.3214],
        [ 1.4025,  0.5967,  0.0127, -1.0765],
        [ 1.1853,  0.4745,  0.7722, -0.3168],
        [ 0.5576,  1.5921,  1.0857, -1.4083],
        [ 0.5540, -0.0416,  0.2223, -1.5959],
        [-0.2880,  0.9004,  0.8823, -1.3644],
        [ 0.7433, -0.1529,  1.8943, -0.1575],
        [-0.7513, -0.8517,  2.5424,  1.2886],
        [ 0.3858, -1.2730,  1.9891,  0.8052],
        [ 0.2512, -0.3950,  0.4897,  1.6176],
        [ 0.4993,  0.1373,  1.1856, -1.8447],
        [ 1.0620,  1.5478,  0.1685, -0.6991],
        [ 1.1182, -0.0938, -1.0712, -0.2523],
        [ 0.0407, -0.3766, -3.6927,  1.5224],
        [ 2.8019, -0.0081,  2.5985, -1.8700],
        [-1.7391,  0.9687,  3.0482,  0.9594],
        [ 0.3914, -0.7096, -1.2333,  1.9392],
        [-0.0873,  0.1559,  1.5123, -0.1904],
        [ 0.2867,  0.1373,  1.4347, -1.5835],
        [ 3.0775,  2.3371, -0.5551, -1.4153],
        [ 1.7803,  4.0771,  0.1822, -0.1500],
        [ 1.7716, -1.4524, -0.6799,  0.7505],
        [-0.2512,  1.6423,  2.7149, -0.7459],
        [ 0.5337,  1.3873, -0.0162,  0.0654],
        [-1.9111,  0.6596,  2.9634, -0.1583],
        [ 0.3654, -0.5669, -0.1434, -0.0710],
        [ 1.5406,  3.3950,  2.0151, -1.0677],
        [ 1.5664,  1.0455,  3.3138, -1.6911]], device='cuda:0') tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
         0,  0], device='cuda:0')
Some discriminator outputs::  tensor([ 2.3479, -0.0409,  1.6757, -0.5040], device='cuda:0') tensor([ 2.6817, -0.0798, -0.2130,  0.8151], device='cuda:0') tensor([ 0.0539, -0.7496, -0.9648,  0.8208], device='cuda:0') tensor([-2.6164, -1.6090, -1.7582,  1.8274], device='cuda:0')
Discriminator aux label size HERE torch.Size([30, 4])
tensor([[ 2.6751,  3.6058,  0.3539, -2.3257],
        [ 1.4460,  2.5104,  0.3672, -1.3746],
        [-0.0963, -1.1462,  0.7930, -0.8311],
        [ 0.9296,  3.0010, -0.4451, -1.3836],
        [ 0.5030, -0.3956, -1.1383,  0.3901],
        [ 1.1939,  0.1538, -1.8340, -1.2526],
        [ 2.9239,  0.6464, -1.6871, -0.5249],
        [ 0.4793, -0.1619,  3.8905, -0.2397],
        [-0.4475,  2.0185, -0.8640,  1.1707],
        [ 1.2971,  0.4420, -1.2604,  0.5251],
        [-0.7576, -1.0798, -0.9998,  0.0918],
        [ 1.9748,  0.6600, -1.4873, -1.2539],
        [ 1.8671,  0.4220,  1.7708, -1.6252],
        [ 0.1858,  0.2473,  0.2928, -0.0792],
        [ 1.4528,  1.5047, -0.4470, -2.1750],
        [ 0.5863,  3.4871,  1.1427, -1.5105],
        [ 1.8274,  0.4182, -0.5903, -0.9047],
        [ 2.4158,  0.2654, -2.6047, -1.0191],
        [-0.3841,  1.3704,  1.2534,  2.4312],
        [ 0.9781,  0.5849, -0.1540,  0.0668],
        [ 0.5239, -0.0960, -0.9732, -0.4343],
        [ 1.8390,  2.7169,  0.1932, -0.7078],
        [ 1.6016,  0.9945,  0.9024, -1.6572],
        [ 3.5467,  2.9215,  1.4500, -0.9465],
        [ 0.8423,  2.5329, -0.3506, -1.6101],
        [ 0.9957,  2.5442,  2.2752, -0.4475],
        [ 4.0281,  2.5033, -0.4755, -2.8545],
        [ 0.5575, -0.6391, -1.6005, -0.9751],
        [ 2.5729,  1.0294, -0.7854, -1.8547],
        [ 2.1343,  2.9090,  2.3457, -1.9736]], device='cuda:0') tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
         0,  0], device='cuda:0')
Some discriminator outputs::  tensor([ 2.6751,  3.6058,  0.3539, -2.3257], device='cuda:0') tensor([ 1.3639,  1.5003, -0.6129, -1.6027], device='cuda:0') tensor([ 0.3532,  0.9916,  0.3515, -1.6495], device='cuda:0') tensor([-1.9349, -1.0370, -1.3444,  1.2769], device='cuda:0')
Discriminator aux label size HERE torch.Size([30, 4])
tensor([[ 0.9410,  1.4843, -1.8546, -2.6560],
        [ 1.7506,  1.4586,  2.0389, -1.2701],
        [ 1.9720,  2.2399,  1.5703, -1.7643],
        [ 0.4955,  0.0386, -0.0342,  0.9902],
        [-0.3112,  2.8252,  2.4852,  0.5666],
        [ 0.7104,  1.7012,  0.9504, -4.3123],
        [ 1.3723, -0.6293,  0.7332, -0.2655],
        [ 2.1470,  2.3791,  1.1253, -0.4405],
        [ 1.7998,  0.6867,  0.5310, -0.5603],
        [ 1.8710,  4.7078, -0.1344, -2.5026],
        [ 4.1396,  0.3955, -0.7015, -0.2698],
        [ 0.6580,  1.9053,  2.0782, -2.4546],
        [-1.4094,  1.6129,  2.0116, -0.9445],
        [ 1.6494,  2.2756,  0.2610, -3.0475],
        [ 2.2275,  1.1792, -0.9336, -1.2117],
        [ 1.2961,  0.5755,  2.7679,  0.3731],
        [-2.2248,  0.6895,  1.3932, -0.1180],
        [-1.3143,  2.1771,  1.0192, -1.3725],
        [ 1.7097,  3.1678,  1.7310, -2.1844],
        [ 2.2782,  1.0216,  1.4551, -2.7540],
        [ 0.1903,  1.1694,  2.5406,  0.3676],
        [ 1.4264,  3.4208, -0.6485, -0.4357],
        [ 0.6458,  1.9659,  0.1346, -0.3451],
        [ 2.0458, -0.5067, -0.1543,  0.1134],
        [-0.0421,  0.6603, -0.9222,  0.6193],
        [ 1.5376,  3.4517,  1.1924, -2.5370],
        [ 2.0753,  1.1643,  0.7837, -1.4708],
        [ 1.5707,  3.0638,  1.2630, -2.2951],
        [ 1.1794, -1.0953, -1.5116,  0.1313],
        [ 1.4028,  1.9149,  0.7545,  0.3431]], device='cuda:0') tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
         0,  0], device='cuda:0')
Some discriminator outputs::  tensor([ 0.9410,  1.4843, -1.8546, -2.6560], device='cuda:0') tensor([ 1.8236,  1.9769, -3.0462, -0.8064], device='cuda:0') tensor([ 0.0196,  1.3379,  1.8978,  0.0088], device='cuda:0') tensor([-3.0233, -1.4913, -0.0753,  2.3188], device='cuda:0')
